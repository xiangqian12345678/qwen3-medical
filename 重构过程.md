# 核心目的

    1.分布式可训练
    2.收集所有可用医疗代码
    3.项目脱敏，不要包含客户项目的任何信息

# 研发步骤

    1.代码调通&注释补充&单机训练脚本  [OK]
      数据集： None的时候处理       [OK]
    2.补充分布式训练脚本              
        完善READM.md 
        如何添加开源数据集，这部分直接在REEADME.md中完整给出样例
        1.GRPO需要验证完整
        2.微调
        3.ORPO 不支持cpu_offload
        DPO 不支持deepspeed
        GRPO cpu_offload模式显存并没有降低
        增量预训练不支持cpu_offload
        PPO
        RM
    3.规范化数据结构+规范化处理脚本

    4.完善研究：
        兼容代码注释
        涉及核心算法研究补充到注释中
    5.数据收集整理
    6.数据处理代码开发
    7.继续优化torchrun
        支持offload_optimizer优化

# 执行脚本

    要构造三类并行计算脚本，例如：
    # torchrun
    torchrun --nproc_per_node=4 ppo_training.py
    
    # deepspeed
    deepspeed --num_gpus=4 ppo_training.py
    
    # accelerate
    accelerate launch --multi_gpu ppo_training.py

### 基于大模型写脚本

    参考脚本
    参考run_orpo.sh,orpo_training.py
        1.基于torchrun实现分布式训练脚本 
        2.支持deepspeed zero2,zero3模式
        3.zero3模式支持cpu_offload
        4.训练脚本写到DPO目录中的ORPO/torchrun_multi_node_multi_gpu.sh中

    参考run_ppo.sh,ppo_training.py
        1.基于torchrun实现分布式训练脚本 
        2.支持deepspeed zero2模式
        3.可以传参数
        4.训练脚本写到DPO目录中的ORPO/torchrun_multi_node_multi_gpu.sh中
        5.支持命令
            1. 单节点多GPU训练:
                bash torchrun_multi_node_multi_gpu.sh
           2. 多节点多GPU训练 (主节点):
              bash torchrun_multi_node_multi_gpu.sh --nnodes 2 --nproc_per_node 8 --node_rank 0 --master_addr 192.168.1.100
           3. 多节点多GPU训练 (工作节点):
              bash torchrun_multi_node_multi_gpu.sh --nnodes 2 --nproc_per_node 8 --node_rank 1 --master_addr 192.168.1.100
           4. 使用DeepSpeed ZeRO-2:
              bash torchrun_multi_node_multi_gpu.sh --nproc_per_node 4 --zero_stage 2

    
    
